{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLjPUgZ67ghr"
      },
      "source": [
        "# Sarcasm Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The dataset\n",
        "News Headlines dataset for Sarcasm Detection is collected from two news websites. TheOnion aims at producing sarcastic versions of current and humorous stories. While it may look like real news at a glance, everything they publish is intentionally fake. Real (and non-sarcastic) news headlines are collected from HuffPost.\n",
        "\n",
        "Each record consists of three attributes:\n",
        "- is_sarcastic: 1 \n",
        "\n",
        "- if the record is sarcastic otherwise 0\n",
        "\n",
        "headline: the headline of the news article\n",
        "\n",
        "article_link: link to the original news article. Useful in collecting supplementary data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/kristinaliu/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import nltk\n",
        "import contractions\n",
        "\n",
        "from transformers import pipeline, DataCollatorWithPadding, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import Dataset, load_dataset\n",
        "import evaluate\n",
        "from evaluate import evaluator\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_document(doc):\n",
        "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    doc = doc.lower()\n",
        "    doc = contractions.fix(doc)\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', ' ', doc, re.I|re.A)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.strip()\n",
        "    \n",
        "    return doc\n",
        "\n",
        "def normalize_corpus(docs):\n",
        "    norm_docs = []\n",
        "    for doc in tqdm(docs):\n",
        "        norm_doc = normalize_document(doc)\n",
        "        norm_docs.append(norm_doc)\n",
        "\n",
        "    return norm_docs\n",
        "\n",
        "def load_pretrained_embeddings(word_to_index, max_features, embedding_size, embedding_file_path):\n",
        "\n",
        "    def get_coefs(word, *arr):\n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    embeddings_index = dict(get_coefs(*row.split(\" \"))\n",
        "                                for row in open(embedding_file_path, encoding=\"utf8\", errors='ignore')\n",
        "                                    if len(row)>100)\n",
        "\n",
        "    all_embs = np.stack(list(embeddings_index.values()))\n",
        "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = min(max_features, len(word_to_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
        "\n",
        "    for word, idx in word_to_index.items():\n",
        "        if idx >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def gen_prediction(model, x_test, y_test):\n",
        "    predictions = model.predict(x_test, batch_size=2048, verbose=0).ravel()\n",
        "    predictions = [1 if prob > 0.5 else 0 for prob in predictions]\n",
        "    acc = accuracy_score(y_test, predictions)*100\n",
        "    print(f\"Accuracy: {acc:.2f}\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "    labels = ['not sarcastic', 'sarcastic']\n",
        "    print(pd.DataFrame(confusion_matrix(y_test, predictions), index=labels, columns=labels))\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2DT1dstWUDg"
      },
      "source": [
        "#### Get and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3gQq7rYWWzM",
        "outputId": "f0ba831b-08ce-436c-c738-c990ba76f945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ytPDo88FEC2ArOjdqErAiarAZBNJzEJz\n",
            "To: /Users/kristinaliu/Documents/NLP/SarcasmDetect.json\n",
            "100%|██████████████████████████████████████| 6.06M/6.06M [00:01<00:00, 3.04MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1ytPDo88FEC2ArOjdqErAiarAZBNJzEJz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OZM68bF-Wdw6",
        "outputId": "c381375f-8ac0-462c-a96e-e111b6db78ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "is_sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "headline",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "article_link",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "2e816738-9cc7-4696-a4fc-108ffe94a3f1",
              "rows": [
                [
                  "9140",
                  "1",
                  "kate middleton suffering from morning sickness",
                  "https://www.theonion.com/kate-middleton-suffering-from-morning-sickness-1819575033"
                ],
                [
                  "25748",
                  "0",
                  "how to take your dream vacation without a guidebook or expensive cell charges",
                  "https://www.huffingtonpost.com/entry/vacation-without-a-guidebook_n_6042084.html"
                ],
                [
                  "26043",
                  "0",
                  "u.s. tourist was detained in north korea  for leaving bible in a bathroom",
                  "https://www.huffingtonpost.com/entry/jeffrey-fowle-north-korea_n_5643464.html"
                ],
                [
                  "3302",
                  "0",
                  "7 tips to exchange gifts and save stress, money",
                  "https://www.huffingtonpost.comhttp://pubx.co/e441n6"
                ],
                [
                  "28337",
                  "0",
                  "how some of trump's bad tweets are helping puppies and kittens",
                  "https://www.huffingtonpost.com/entry/trump-and-dump-bot-tweets-puppies_us_58926f94e4b070cf8b80a006"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9140</th>\n",
              "      <td>1</td>\n",
              "      <td>kate middleton suffering from morning sickness</td>\n",
              "      <td>https://www.theonion.com/kate-middleton-suffer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25748</th>\n",
              "      <td>0</td>\n",
              "      <td>how to take your dream vacation without a guid...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/vacation-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26043</th>\n",
              "      <td>0</td>\n",
              "      <td>u.s. tourist was detained in north korea  for ...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jeffrey-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3302</th>\n",
              "      <td>0</td>\n",
              "      <td>7 tips to exchange gifts and save stress, money</td>\n",
              "      <td>https://www.huffingtonpost.comhttp://pubx.co/e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28337</th>\n",
              "      <td>0</td>\n",
              "      <td>how some of trump's bad tweets are helping pup...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/trump-and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic                                           headline  \\\n",
              "9140              1     kate middleton suffering from morning sickness   \n",
              "25748             0  how to take your dream vacation without a guid...   \n",
              "26043             0  u.s. tourist was detained in north korea  for ...   \n",
              "3302              0    7 tips to exchange gifts and save stress, money   \n",
              "28337             0  how some of trump's bad tweets are helping pup...   \n",
              "\n",
              "                                            article_link  \n",
              "9140   https://www.theonion.com/kate-middleton-suffer...  \n",
              "25748  https://www.huffingtonpost.com/entry/vacation-...  \n",
              "26043  https://www.huffingtonpost.com/entry/jeffrey-f...  \n",
              "3302   https://www.huffingtonpost.comhttp://pubx.co/e...  \n",
              "28337  https://www.huffingtonpost.com/entry/trump-and...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_json('./SarcasmDetect.json', lines=True)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmRclPlP7gh4"
      },
      "source": [
        "#### Remove all records with no headline text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "myWq442E7gh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28619 entries, 0 to 28618\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   is_sarcastic  28619 non-null  int64 \n",
            " 1   headline      28619 non-null  object\n",
            " 2   article_link  28619 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 670.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df = df[df['headline'] != '']\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = df['headline']\n",
        "y = df['is_sarcastic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "is_sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "proportion",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "c524b9e3-efb9-439b-83d0-5c06c3ea7b11",
              "rows": [
                [
                  "0",
                  "0.523603200670883"
                ],
                [
                  "1",
                  "0.476396799329117"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 2
              }
            },
            "text/plain": [
              "is_sarcastic\n",
              "0    0.523603\n",
              "1    0.476397\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalize corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28619/28619 [00:00<00:00, 138022.02it/s]\n"
          ]
        }
      ],
      "source": [
        "corpus_clean = normalize_corpus(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(corpus_clean, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2))\n",
        "tv_xtrain = tv.fit_transform(X_train)\n",
        "tv_xtest = tv.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instantiate model\n",
        "model_lr = LogisticRegression(penalty='l2', max_iter=500, C=1,\n",
        "                        solver='lbfgs', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kristinaliu/Applications/anaconda3/envs/llm_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_lr.fit(tv_xtrain, y_train.values)\n",
        "tfidf_predictions_lr = model_lr.predict(tv_xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84      4455\n",
            "           1       0.82      0.83      0.83      4131\n",
            "\n",
            "    accuracy                           0.83      8586\n",
            "   macro avg       0.83      0.83      0.83      8586\n",
            "weighted avg       0.83      0.83      0.83      8586\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "not sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "bdee698b-3b2a-409f-9df7-341a2805fc53",
              "rows": [
                [
                  "not sarcastic",
                  "3712",
                  "743"
                ],
                [
                  "sarcastic",
                  "702",
                  "3429"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>not sarcastic</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>not sarcastic</th>\n",
              "      <td>3712</td>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sarcastic</th>\n",
              "      <td>702</td>\n",
              "      <td>3429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               not sarcastic  sarcastic\n",
              "not sarcastic           3712        743\n",
              "sarcastic                702       3429"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = ['not sarcastic', 'sarcastic']\n",
        "acc_lr = accuracy_score(y_test, tfidf_predictions_lr)*100\n",
        "print(classification_report(y_test, tfidf_predictions_lr))\n",
        "pd.DataFrame(confusion_matrix(y_test, tfidf_predictions_lr), index=labels, columns=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instantiate model\n",
        "model_rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "\n",
        "# train model\n",
        "model_rf.fit(tv_xtrain, y_train)\n",
        "\n",
        "# predict on test data\n",
        "tfidf_predictions_rf = model_rf.predict(tv_xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.80      4455\n",
            "           1       0.78      0.82      0.80      4131\n",
            "\n",
            "    accuracy                           0.80      8586\n",
            "   macro avg       0.80      0.80      0.80      8586\n",
            "weighted avg       0.80      0.80      0.80      8586\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "not sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "4acbaed5-15ad-49ea-8afd-e5b5f281c6f1",
              "rows": [
                [
                  "not sarcastic",
                  "3476",
                  "979"
                ],
                [
                  "sarcastic",
                  "732",
                  "3399"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>not sarcastic</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>not sarcastic</th>\n",
              "      <td>3476</td>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sarcastic</th>\n",
              "      <td>732</td>\n",
              "      <td>3399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               not sarcastic  sarcastic\n",
              "not sarcastic           3476        979\n",
              "sarcastic                732       3399"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = ['not sarcastic', 'sarcastic']\n",
        "acc_rf = accuracy_score(y_test, tfidf_predictions_rf)*100\n",
        "print(classification_report(y_test, tfidf_predictions_rf))\n",
        "pd.DataFrame(confusion_matrix(y_test, tfidf_predictions_rf), index=labels, columns=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_xgb = xgb.XGBClassifier(n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_xgb.fit(tv_xtrain, y_train)\n",
        "predictions_xgb = model_xgb.predict(tv_xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.74      0.78      4455\n",
            "           1       0.75      0.84      0.79      4131\n",
            "\n",
            "    accuracy                           0.79      8586\n",
            "   macro avg       0.79      0.79      0.79      8586\n",
            "weighted avg       0.79      0.79      0.79      8586\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "not sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sarcastic",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "aceca6ff-81a2-491e-b70a-83c521d1b13e",
              "rows": [
                [
                  "not sarcastic",
                  "3288",
                  "1167"
                ],
                [
                  "sarcastic",
                  "643",
                  "3488"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 2
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>not sarcastic</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>not sarcastic</th>\n",
              "      <td>3288</td>\n",
              "      <td>1167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sarcastic</th>\n",
              "      <td>643</td>\n",
              "      <td>3488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               not sarcastic  sarcastic\n",
              "not sarcastic           3288       1167\n",
              "sarcastic                643       3488"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = ['not sarcastic', 'sarcastic']\n",
        "acc_xgb = accuracy_score(y_test, predictions_xgb)*100\n",
        "print(classification_report(y_test, predictions_xgb))\n",
        "pd.DataFrame(confusion_matrix(y_test, predictions_xgb), index=labels, columns=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep learning models\n",
        "### Preprocess text for DL models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size=22132\n",
            "Number of Documents=20033\n"
          ]
        }
      ],
      "source": [
        "# Tokenize sequences\n",
        "t = Tokenizer(oov_token='<UNK>')\n",
        "t.fit_on_texts(X_train)\n",
        "t.word_index['<PAD>'] = 0\n",
        "train_sequences = t.texts_to_sequences(X_train)\n",
        "test_sequences = t.texts_to_sequences(X_test)\n",
        "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
        "print(\"Number of Documents={}\".format(t.document_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualise length of each sequence\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "train_lens = [len(s) for s in train_sequences]\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
        "h1 = ax.hist(train_lens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20033, 23), (8586, 23))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pad sequences to sensible length observed in plt\n",
        "MAX_SEQUENCE_LENGTH = 23\n",
        "X_train_pad = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "X_test_pad = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH,  padding='post')\n",
        "X_train_pad.shape, X_test_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters for embedding layer\n",
        "VOCAB_SIZE = len(t.word_index)\n",
        "EMBED_SIZE = 300 # word embedding size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters for model training\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=128\n",
        "\n",
        "# Callback for early stopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                      patience=5,\n",
        "                                      restore_best_weights=True,\n",
        "                                      verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kristinaliu/Applications/anaconda3/envs/llm_env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"CNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create the model\n",
        "model_cnn = Sequential(name='CNN')\n",
        "\n",
        "model_cnn.add(Embedding(VOCAB_SIZE,\n",
        "                    EMBED_SIZE,\n",
        "                    input_length=MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "model_cnn.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn.add(Flatten())\n",
        "\n",
        "model_cnn.add(Dense(256, activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dropout(0.25))\n",
        "model_cnn.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_cnn.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_cnn.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_cnn.fit(X_train_pad, y_train,\n",
        "          validation_split=0.2,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          callbacks=[es],\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 84.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.81      0.85      4455\n",
            "           1       0.81      0.89      0.85      4131\n",
            "\n",
            "    accuracy                           0.85      8586\n",
            "   macro avg       0.85      0.85      0.85      8586\n",
            "weighted avg       0.85      0.85      0.85      8586\n",
            "\n",
            "               not sarcastic  sarcastic\n",
            "not sarcastic           3617        838\n",
            "sarcastic                454       3677\n"
          ]
        }
      ],
      "source": [
        "acc_cnn = gen_prediction(model_cnn, X_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use FastText embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2idx = t.word_index\n",
        "FASTTEXT_INIT_EMBEDDINGS_FILE = Path('..', 'embeddings', 'crawl-300d-2M-subword.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22132, 300)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ft_embeddings = load_pretrained_embeddings(word_to_index=word2idx,\n",
        "                                           max_features=VOCAB_SIZE,\n",
        "                                           embedding_size=EMBED_SIZE,\n",
        "                                           embedding_file_path=FASTTEXT_INIT_EMBEDDINGS_FILE)\n",
        "ft_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using same model than in live coding \n",
        "model_cnn_ft = tf.keras.models.Sequential(name='CNN-FastText')\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
        "                                    weights=[ft_embeddings],\n",
        "                                    trainable=True,\n",
        "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Conv1D(filters=256, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn_ft.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn_ft.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model_cnn_ft.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_cnn_ft.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_cnn_ft.add(tf.keras.layers.Dropout(0.25))\n",
        "model_cnn_ft.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_cnn_ft.add(tf.keras.layers.Dropout(0.25))\n",
        "model_cnn_ft.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_cnn_ft.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_cnn_ft.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6777 - loss: 0.5580 - val_accuracy: 0.8682 - val_loss: 0.3148\n",
            "Epoch 2/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1516 - val_accuracy: 0.8700 - val_loss: 0.3578\n",
            "Epoch 3/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0327 - val_accuracy: 0.8538 - val_loss: 0.5341\n",
            "Epoch 4/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 0.8550 - val_loss: 0.6673\n",
            "Epoch 5/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.8495 - val_loss: 0.9268\n",
            "Epoch 6/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0087 - val_accuracy: 0.8510 - val_loss: 0.7140\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f01542c1ac0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_cnn_ft.fit(X_train_pad, y_train,\n",
        "          validation_split=0.2,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          callbacks=[es],\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.48\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87      4455\n",
            "           1       0.87      0.84      0.86      4131\n",
            "\n",
            "    accuracy                           0.86      8586\n",
            "   macro avg       0.87      0.86      0.86      8586\n",
            "weighted avg       0.87      0.86      0.86      8586\n",
            "\n",
            "               not sarcastic  sarcastic\n",
            "not sarcastic           3958        497\n",
            "sarcastic                664       3467\n"
          ]
        }
      ],
      "source": [
        "acc_cnn_ft = gen_prediction(model_cnn_ft, X_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/janp/miniforge3/envs/nlp3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"LSTM\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m6,639,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> (25.33 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,639,600\u001b[0m (25.33 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> (25.33 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,639,600\u001b[0m (25.33 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "LSTM_DIM = 128 # the number of hidden units in each LSTM cell i.e the hidden state embedding size;\n",
        "\n",
        "model_lstm = tf.keras.models.Sequential(name=\"LSTM\")\n",
        "\n",
        "model_lstm.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
        "                                    weights=[ft_embeddings],\n",
        "                                    trainable=True,\n",
        "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "model_lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))) # to use bidirectional lstms\n",
        "\n",
        "# model.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
        "\n",
        "model_lstm.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "model_lstm.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_lstm.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7195 - loss: 0.5174 - val_accuracy: 0.8453 - val_loss: 0.3430\n",
            "Epoch 2/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9326 - loss: 0.1765 - val_accuracy: 0.8612 - val_loss: 0.3551\n",
            "Epoch 3/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9816 - loss: 0.0621 - val_accuracy: 0.8485 - val_loss: 0.4663\n",
            "Epoch 4/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0191 - val_accuracy: 0.8455 - val_loss: 0.5885\n",
            "Epoch 5/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9968 - loss: 0.0119 - val_accuracy: 0.8395 - val_loss: 0.8129\n",
            "Epoch 6/20\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9959 - loss: 0.0103 - val_accuracy: 0.8340 - val_loss: 0.8624\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eff5453a510>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_lstm.fit(X_train_pad, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "          callbacks=[es],\n",
        "          shuffle=True, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 85.16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.78      0.85      4455\n",
            "           1       0.80      0.93      0.86      4131\n",
            "\n",
            "    accuracy                           0.85      8586\n",
            "   macro avg       0.86      0.85      0.85      8586\n",
            "weighted avg       0.86      0.85      0.85      8586\n",
            "\n",
            "               not sarcastic  sarcastic\n",
            "not sarcastic           3488        967\n",
            "sarcastic                307       3824\n"
          ]
        }
      ],
      "source": [
        "acc_lstm = gen_prediction(model_lstm, X_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/janp/miniforge3/envs/nlp3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRU\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"GRU\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m6,639,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> (25.33 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,639,600\u001b[0m (25.33 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,639,600</span> (25.33 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,639,600\u001b[0m (25.33 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "GRU_DIM = 1024 # the number of hidden units in each LSTM cell i.e the hidden state embedding size;\n",
        "\n",
        "model_gru = tf.keras.models.Sequential(name=\"GRU\")\n",
        "\n",
        "model_gru.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
        "                                    weights=[ft_embeddings],\n",
        "                                    trainable=True,\n",
        "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
        "model_gru.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model_gru.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(GRU_DIM, return_sequences=True))) # to use bidirectional lstms\n",
        "model_gru.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(GRU_DIM, return_sequences=False))) # to use bidirectional lstms\n",
        "\n",
        "# model.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
        "\n",
        "model_gru.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "# model_gru.add(tf.keras.layers.Dropout(0.2))\n",
        "model_gru.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_gru.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.7293 - loss: 0.5213 - val_accuracy: 0.8568 - val_loss: 0.3472\n",
            "Epoch 2/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9109 - loss: 0.2195 - val_accuracy: 0.8643 - val_loss: 0.3236\n",
            "Epoch 3/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - accuracy: 0.9603 - loss: 0.1074 - val_accuracy: 0.8563 - val_loss: 0.3955\n",
            "Epoch 4/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9793 - loss: 0.0571 - val_accuracy: 0.8473 - val_loss: 0.5352\n",
            "Epoch 5/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9884 - loss: 0.0331 - val_accuracy: 0.8373 - val_loss: 0.5205\n",
            "Epoch 6/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9910 - loss: 0.0266 - val_accuracy: 0.8368 - val_loss: 0.7569\n",
            "Epoch 7/20\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.9950 - loss: 0.0143 - val_accuracy: 0.8373 - val_loss: 0.8124\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7efeaa069220>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_gru.fit(X_train_pad, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "          callbacks=[es],\n",
        "          shuffle=True, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 86.98\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      4455\n",
            "           1       0.86      0.87      0.87      4131\n",
            "\n",
            "    accuracy                           0.87      8586\n",
            "   macro avg       0.87      0.87      0.87      8586\n",
            "weighted avg       0.87      0.87      0.87      8586\n",
            "\n",
            "               not sarcastic  sarcastic\n",
            "not sarcastic           3876        579\n",
            "sarcastic                539       3592\n"
          ]
        }
      ],
      "source": [
        "acc_gru = gen_prediction(model_gru, X_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
        "\n",
        "    all_ids, all_masks, all_segments= [], [], []\n",
        "    for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
        "\n",
        "        tokens = tokenizer.tokenize(doc)\n",
        "\n",
        "        if len(tokens) > max_seq_length-2:\n",
        "            tokens = tokens[0 : (max_seq_length-2)]\n",
        "        # with newer versions of transformers you don't need to explicitely add CLS and SEP\n",
        "        # they are automatically added by the tokenizer\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        masks = [1] * len(ids) # [1,1,1.....] # < 500 ones\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        while len(ids) < max_seq_length:\n",
        "            ids.append(0)\n",
        "            masks.append(0)\n",
        "\n",
        "        segments = [0] * max_seq_length # [0,0,0...] # 500 zeros\n",
        "        all_ids.append(ids)\n",
        "        all_masks.append(masks)\n",
        "        all_segments.append(segments)\n",
        "\n",
        "    encoded = np.array([all_ids, all_masks, all_segments])\n",
        "\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(corpus_clean, y, train_size=0.7, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting docs to features: 100%|██████████| 20033/20033 [00:02<00:00, 8034.44it/s]\n",
            "Converting docs to features: 100%|██████████| 8586/8586 [00:00<00:00, 9989.54it/s] \n"
          ]
        }
      ],
      "source": [
        "train_features_ids, train_features_masks, train_features_segments = create_bert_input_features(tokenizer,\n",
        "                                                                                               X_train,\n",
        "                                                                                               max_seq_length=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "test_features_ids, test_features_masks, test_features_segments = create_bert_input_features(tokenizer,\n",
        "                                                                                               X_test,\n",
        "                                                                                               max_seq_length=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ bert_input_ids      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_input_masks    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_segment_ids    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ bert_input_masks… │\n",
              "│                     │                   │            │ bert_segment_ids… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ bert_input_ids      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_input_masks    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bert_segment_ids    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m768\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bert_input_ids[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ bert_input_masks… │\n",
              "│                     │                   │            │ bert_segment_ids… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │    \u001b[38;5;34m196,864\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │     \u001b[38;5;34m65,792\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │        \u001b[38;5;34m257\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,913</span> (1.00 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m262,913\u001b[0m (1.00 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,913</span> (1.00 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,913\u001b[0m (1.00 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build BERT model\n",
        "bert_model = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "inp_id = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
        "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
        "inp_segment = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"bert_segment_ids\")\n",
        "inputs = [inp_id, inp_mask, inp_segment]\n",
        "\n",
        "def bert_layer(inputs):\n",
        "    return bert_model(input_ids=inputs[0], attention_mask=inputs[1], token_type_ids=inputs[2])\n",
        "\n",
        "bert_outputs = tf.keras.layers.Lambda(bert_layer, output_shape=(MAX_SEQUENCE_LENGTH, 768))([inp_id, inp_mask, inp_segment])\n",
        "\n",
        "pooled_output = bert_outputs[1]\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
        "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
        "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
        "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
        "\n",
        "model_bert = tf.keras.Model(inputs=[inp_id, inp_mask, inp_segment], outputs=output)\n",
        "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5,\n",
        "                                           epsilon=1e-08),\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_bert.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1740757295.437490  363940 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "2025-02-28 16:41:37.586074: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 32 bytes spill stores, 32 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:37.776630: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 340 bytes spill stores, 308 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:38.020409: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12431', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:38.274055: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7_0', 1548 bytes spill stores, 1804 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1066/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5535 - loss: 0.6881"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1740757306.771994  363935 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "2025-02-28 16:41:48.185569: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 32 bytes spill stores, 32 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:48.256741: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 340 bytes spill stores, 308 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:48.815557: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7_0', 1548 bytes spill stores, 1804 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:48.936885: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12431', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5536 - loss: 0.6880"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1740757311.881280  363935 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "W0000 00:00:1740757315.552479  363938 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "2025-02-28 16:41:56.440321: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2', 32 bytes spill stores, 32 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:56.560082: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2_0', 124 bytes spill stores, 132 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:56.563520: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2', 340 bytes spill stores, 308 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:56.868026: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2_0', 244 bytes spill stores, 244 bytes spill loads\n",
            "\n",
            "2025-02-28 16:41:57.297344: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5753', 84 bytes spill stores, 84 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5536 - loss: 0.6880 - val_accuracy: 0.7108 - val_loss: 0.6063\n",
            "Epoch 2/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6685 - loss: 0.6154 - val_accuracy: 0.7562 - val_loss: 0.5489\n",
            "Epoch 3/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7147 - loss: 0.5677 - val_accuracy: 0.7587 - val_loss: 0.5210\n",
            "Epoch 4/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7361 - loss: 0.5360 - val_accuracy: 0.7764 - val_loss: 0.5017\n",
            "Epoch 5/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7581 - loss: 0.5147 - val_accuracy: 0.7731 - val_loss: 0.4951\n",
            "Epoch 6/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.5010 - val_accuracy: 0.7856 - val_loss: 0.4775\n",
            "Epoch 7/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7667 - loss: 0.4890 - val_accuracy: 0.7764 - val_loss: 0.4752\n",
            "Epoch 8/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7694 - loss: 0.4772 - val_accuracy: 0.7899 - val_loss: 0.4635\n",
            "Epoch 9/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7781 - loss: 0.4773 - val_accuracy: 0.7914 - val_loss: 0.4612\n",
            "Epoch 10/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7729 - loss: 0.4729 - val_accuracy: 0.7951 - val_loss: 0.4456\n",
            "Epoch 11/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7833 - loss: 0.4625 - val_accuracy: 0.7999 - val_loss: 0.4433\n",
            "Epoch 12/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 0.4523 - val_accuracy: 0.7906 - val_loss: 0.4528\n",
            "Epoch 13/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7899 - loss: 0.4507 - val_accuracy: 0.8028 - val_loss: 0.4322\n",
            "Epoch 14/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7856 - loss: 0.4463 - val_accuracy: 0.8076 - val_loss: 0.4298\n",
            "Epoch 15/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7894 - loss: 0.4445 - val_accuracy: 0.8038 - val_loss: 0.4275\n",
            "Epoch 16/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7953 - loss: 0.4416 - val_accuracy: 0.8003 - val_loss: 0.4278\n",
            "Epoch 17/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7964 - loss: 0.4341 - val_accuracy: 0.8021 - val_loss: 0.4232\n",
            "Epoch 18/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7972 - loss: 0.4334 - val_accuracy: 0.8126 - val_loss: 0.4196\n",
            "Epoch 19/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.8005 - loss: 0.4260 - val_accuracy: 0.8073 - val_loss: 0.4242\n",
            "Epoch 20/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7996 - loss: 0.4303 - val_accuracy: 0.8171 - val_loss: 0.4103\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f004c7f6660>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_bert.fit([train_features_ids,\n",
        "           train_features_masks,\n",
        "           train_features_segments], y_train, \n",
        "           validation_split=0.2, epochs=20,\n",
        "           batch_size=15,\n",
        "           shuffle=True,\n",
        "           verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1740757546.999251  363939 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "2025-02-28 16:45:47.811018: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2554', 264 bytes spill stores, 264 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:47.853763: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2554', 68 bytes spill stores, 68 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:48.127753: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2554_0', 776 bytes spill stores, 724 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:48.226881: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2554', 324 bytes spill stores, 324 bytes spill loads\n",
            "\n",
            "W0000 00:00:1740757551.859393  363938 assert_op.cc:38] Ignoring Assert operator functional_4_1/lambda_1/tf_bert_model/bert/embeddings/assert_less/Assert/Assert\n",
            "2025-02-28 16:45:52.915450: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743', 12 bytes spill stores, 12 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:52.932871: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743', 68 bytes spill stores, 68 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:52.967447: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743_0', 272 bytes spill stores, 272 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:53.146341: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743', 392 bytes spill stores, 392 bytes spill loads\n",
            "\n",
            "2025-02-28 16:45:53.221104: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5743_0', 756 bytes spill stores, 708 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 80.84\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      4455\n",
            "           1       0.79      0.81      0.80      4131\n",
            "\n",
            "    accuracy                           0.81      8586\n",
            "   macro avg       0.81      0.81      0.81      8586\n",
            "weighted avg       0.81      0.81      0.81      8586\n",
            "\n",
            "               not sarcastic  sarcastic\n",
            "not sarcastic           3585        870\n",
            "sarcastic                775       3356\n"
          ]
        }
      ],
      "source": [
        "acc_bert = gen_prediction(model_bert, [test_features_ids,\n",
        "           test_features_masks,\n",
        "           test_features_segments], y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualise results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc_list = [acc_lr, acc_rf, acc_xgb, acc_cnn, acc_cnn_ft, acc_lstm, acc_gru, acc_bert]\n",
        "acc_labels = [\"LogisticRegression\", \"RandomForest\", \"XGBoost\", \"CNN\", \"CNNFastText\", \"LSTM\", \"GRU\", \"BERT\"]\n",
        "acc_dict = {k: v for k, v in zip(acc_labels, acc_list)} \n",
        "df_acc = pd.DataFrame(acc_dict, index=range(0, 1)).melt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(df_acc, x=\"variable\", y=\"value\", hue=\"variable\")\n",
        "ax.set_xticks(acc_labels)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "ax.set_xlabel(\"Model\")\n",
        "ax.set_ylabel(\"Accuracy (%)\")\n",
        "ax.axhline(50, linestyle=\"--\", color=\"k\", alpha=0.5)\n",
        "None"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
